<html style=font-family:arial><head><title>ApplyThreshold</title></head><body><h1>Module: ApplyThreshold</h1><div><b>Apply Threshold</b> sets pixel intensities below or above a certain threshold to zero <hr> <b>ApplyThreshold</b> produces either a grayscale or binary image based on a threshold which can be pre-selected or calculated automatically using one of many methods. </div><div><h2>Settings:</h2><h4>Select the input image</h4><div>
            Choose the image to be thresholded.</div><h4>Name the output image</h4><div>
            Enter a name for the thresholded image.</div><h4>Select the output image type</h4><div>
            Two types of output images can be produced:<br>
            <ul>
            <li><i>Grayscale:</i> The pixels that are retained after some pixels 
            are set to zero or shifted (based on your selections for thresholding 
            options) will have their original 
            intensity values.</li>
            <li><i>Binary (black and white):</i> The pixels that are retained after some pixels are 
            set to zero (based on your selections for thresholding options) will be 
            white and all other pixels will be black (zeroes).</li>
            </ul></div><h4>Set pixels below or above the threshold to zero?</h4><div>
            <i>(Used only when "Grayscale" thresholding is selected)</i><br>
            For grayscale output, the dim pixels below 
            the threshold can be set to zero or the bright pixels above 
            the threshold can be set to zero.
            Choose <i>Below threshold</i> to threshold dim pixels and
            <i>Above threshold</i> to threshold bright pixels.</div><h4>Subtract the threshold value from the remaining pixel intensities?</h4><div>
            <i>(Used only if the output image is Grayscale and pixels below a given intensity are to be set to zero)</i><br>
            Select <i>Yes</i> to shift the value of the dim pixels by the threshold value.</div><h4>Number of pixels by which to expand the thresholding around those excluded bright pixels</h4><div>
            <i>(Used only if the output image is grayscale and pixels above a given intensity are to be set to zero)</i><br>
            This setting is useful when attempting to exclude bright artifactual objects: 
            first, set the threshold to exclude these bright objects; it may also be desirable to expand the
            thresholded region around those bright objects by a certain distance so as to avoid a "halo" effect.</div><h4>Threshold strategy</h4><div>
            The thresholding strategy determines the type of input that is used
            to calculate the threshold. The image thresholds can be based on:
            <ul>
            <li>The pixel intensities of the input image (this is the most common).</li>
            <li>A single value manually provided by the user.</li>
            <li>A single value produced by a prior module measurement.</li>
            <li>A binary image (called a <i>mask</i>) where some of the pixel intensity 
            values are set to 0, and others are set to 1.</li>
            </ul>
            These options allow you to calculate a threshold based on the whole 
            image or based on image sub-regions such as user-defined masks or
            objects supplied by a prior module.
            <br>
            The choices for the threshold strategy are:
            <br><ul>
            <li><i>Automatic:</i> Use the default settings for
            thresholding. This strategy calculates the threshold using the MCT method
            on the whole image (see below for details on this method) and applies the 
            threshold to the image, smoothed with a Gaussian with sigma of 1.
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            This approach is fairly robust, but does not allow you to select the threshold
            algorithm and does not allow you to apply additional corrections to the
            threshold.</dd>
            </dl></li>
            
            <li><i>Global:</i> Calculate a single threshold value based on
            the unmasked pixels of the input image and use that value
            to classify pixels above the threshold as foreground and below
            as background.
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            This strategy is fast and robust, especially if
            the background is uniformly illuminated.</dd>
            </dl></li>
            
            <li><i>Adaptive:</i> Partition the input image into tiles
            and calculate thresholds for each tile. For each tile, the calculated
            threshold is applied only to the pixels within that tile. <br>
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            This method is slower but can produce better results for non-uniform backgrounds.
            However, for signifcant illumination variation, using the <b>CorrectIllumination</b>
            modules is preferable.</dd>
            </dl></li>
            
            <li><i>Per object:</i> Use objects from a prior module
            such as <b>IdentifyPrimaryObjects</b> to define the region of interest
            to be thresholded. Calculate a separate threshold for each object and 
            then apply that threshold to pixels within the object. The pixels outside 
            the objects are classified as background.
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            This method can be useful for identifying sub-cellular particles or 
            single-molecule probes if the background intensity varies from cell to cell
            (e.g., autofluorescence or other mechanisms).</dd>
            </dl></li>
            
            <li><i>Manual:</i> Enter a single value between zero and
            one that applies to all cycles and is independent of the input
            image.
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            This approach is useful if the input image has a stable or
            negligible background, or if the input image is the probability
            map output of the <b>ClassifyPixels</b> module (in which case, a value
            of 0.5 should be chosen). If the input image is already binary (i.e.,
            where the foreground is 1 and the background is 0), a manual value 
            of 0.5 will identify the objects.</dd>
            </dl></li>
            
            <li><i>Binary image:</i> Use a binary image to classify
            pixels as foreground or background. Pixel values other than zero
            will be foreground and pixel values that are zero will be
            background. This method can be used to import a ground-truth segmentation created 
            by CellProfiler or another program. 
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            The most typical approach to produce a 
            binary image is to use the <b>ApplyThreshold</b> module (image as input, 
            image as output) or the <b>ConvertObjectsToImage</b> module (objects as input, 
            image as output); both have options to produce a binary image. It can also be 
            used to create objects from an image mask produced by other CellProfiler 
            modules, such as <b>Morph</b>. Note that even though no algorithm is actually 
            used to find the threshold in this case, the final threshold value is reported 
            as the <i>Otsu</i> threshold calculated for the foreground region.</dd>
            </dl></li>
            
            <li><i>Measurement:</i> Use a prior image measurement as the
            threshold. The measurement should have values between zero and one.
            This strategy can be used to apply a pre-calculated threshold imported 
            as per-image metadata via the <b>Metadata</b> module.
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            Like manual thresholding, this approach can be useful when you are certain what 
            the cutoff should be. The difference in this case is that the desired threshold does 
            vary from image to image in the experiment but can be measured using another module,
            such as one of the <b>Measure</b> modules, <b>ApplyThreshold</b> or
            an <b>Identify</b> module.</dd>
            </dl></li>
            </ul>
	    </div><h4>Thresholding method</h4><div>
            The intensity threshold affects the decision of whether each pixel
            will be considered foreground (region(s) of interest) or background.
            A higher threshold value will result in only the brightest regions being identified, 
            whereas a lower threshold value will include dim regions. You can have the threshold 
            automatically calculated from a choice of several methods, 
            or you can enter a number manually between 0 and 1 for the threshold.
            
            <p>Both the automatic and manual options have advantages and disadvantages. 
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            An automatically-calculated threshold adapts to changes in
            lighting/staining conditions between images and is usually more
            robust/accurate. In the vast majority of cases, an automatic method
            is sufficient to achieve the desired thresholding, once the proper
            method is selected.</dd>
            <dd>In contrast, an advantage of a manually-entered number is that it treats every image identically,
            so use this option when you have a good sense for what the threshold should be
            across all images. To help determine the choice of threshold manually, you
            can inspect the pixel intensities in an image of your choice. 
            To view pixel intensities in an open image, use the 
pixel intensity tool which is available in any open display window. When you move 
your mouse over the image, the pixel intensities will appear in the bottom bar of the display window.. </dd>
            <dd><img src="images\thumb-down.png">&nbsp;
            The manual method is not robust with regard to slight changes in lighting/staining 
            conditions between images. </dd>
            <dd>The automatic methods may ocasionally produce a poor 
            threshold for unusual or artifactual images. It also takes a small amount of time to
            calculate, which can add to processing time for analysis runs on a large
            number of images.</dd>
            </dl></p>
            
            <p>The threshold that is used for each image is recorded as a per-image 
            measurement, so if you are surprised by unusual measurements from
            one of your images, you might check whether the automatically calculated
            threshold was unusually high or low compared to the other images. See the
            <b>FlagImage</b> module if you would like to flag an image based on the threshold
            value.</p>
            
            <p>There are a number of methods for finding thresholds automatically:
            <ul>
            <li><i>Otsu:</i> This approach calculates the threshold separating the
            two classes of pixels (foreground and background) by minimizing the variance within the 
            each class.
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            This method is a good initial approach if you do not know much about
            the image characteristics of all the images in your experiment, 
            especially if the percentage of the image covered by foreground varies 
            substantially from image to image. </dd>
            </dl>
            <dl>
            <dd><img src="images\gear.png">&nbsp;
            Our implementation of Otsu's method allows for assigning the threhsold value based on
            splitting the image into either two classes (foreground and background) or three classes 
            (foreground, mid-level, and background). See the help below for more details.</dd>
            </dl>
            </li>
            
            <li><i>Mixture of Gaussian (MoG):</i>This function assumes that the 
            pixels in the image belong to either a background class or a foreground
            class, using an initial guess of the fraction of the image that is 
            covered by foreground. 
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            If you know that the percentage of each image that is foreground does not 
            vary much from image to image, the MoG method can be better, especially if the 
            foreground percentage is not near 50%.</dd>
            </dl>
            <dl>
            <dd><img src="images\gear.png">&nbsp;
            This method is our own version of a Mixture of Gaussians
            algorithm (<i>O. Friman, unpublished</i>). Essentially, there are two steps:
            <ol><li>First, a number of Gaussian distributions are estimated to 
            match the distribution of pixel intensities in the image. Currently 
            three Gaussian distributions are fitted, one corresponding to a 
            background class, one corresponding to a foreground class, and one 
            distribution for an intermediate class. The distributions are fitted
            using the Expectation-Maximization algorithm, a procedure referred 
            to as Mixture of Gaussians modeling. </li>
            <li>When the three Gaussian distributions have been fitted, a decision 
            is made whether the intermediate class more closely models the background pixels 
            or foreground pixels, based on the estimated fraction provided by the user.</li></ol></dd>
            </dl>
            </li>
            
            <li><i>Background:</i> This method simply finds the mode of the 
            histogram of the image, which is assumed to be the background of the 
            image, and chooses a threshold at twice that value (which you can 
            adjust with a Threshold Correction Factor; see below).  The calculation 
	    includes those pixels between 2% and 98% of the intensity range. 
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            This thresholding method is appropriate for images in which most of the image is background. 
	    It can also be helpful if your images vary in overall brightness, but the objects of 
            interest are consistently <i>N</i> times brighter than the background level of the image.</dd>
            </dl></li>
            
            <li><i>RobustBackground:</i> Much like the Background: method, this method is 
	    also simple and assumes that the background distribution
	    approximates a Gaussian by trimming the brightest and dimmest 5% of pixel 
	    intensities. It then calculates the mean and standard deviation of the 
            remaining pixels and calculates the threshold as the mean + 2 times 
            the standard deviation. 
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            This thresholding method can be helpful if the majority
	    of the image is background, and the results are often comparable or better than the
	    <i>Background</i> method.</dd></dl></li>
            
            <li><i>RidlerCalvard:</i> This method is simple and its results are
            often very similar to <i>Otsu</i>. 
            <i>RidlerCalvard</i> chooses an initial threshold and then iteratively 
            calculates the next one by taking the mean of the average intensities of 
            the background and foreground pixels determined by the first threshold. 
            The algorithm then repeats this process until the threshold converges to a single value.
            <dl>
            <dd></dd>
            <dd><img src="images\gear.png">&nbsp;
            This is an implementation of the method described in Ridler and Calvard, 1978. 
            According to Sezgin and Sankur 2004, Otsu's 
            overall quality on testing 40 nondestructive testing images is slightly 
            better than Ridler's (average error: Otsu, 0.318; Ridler, 0.401).</dd>
            </dl>
            </li>
            
            <li><i>Kapur:</i> This method computes the threshold of an image by 
            searching for the threshold that maximizes the sum of entropies of the foreground 
            and background pixel values, when treated as separate distributions.
            <dl>
            <dd><img src="images\gear.png">&nbsp;
            This is an implementation of the method described in Kapur <i>et al</i>, 1985.</dd>
            </dl></li>
            
            <li><i>Maximum correlation thresholding (MCT):</i> This method computes 
            the maximum correlation between the binary mask created by thresholding and
            the thresholded image and is somewhat similar mathematically to <i>Otsu</i>. 
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            The authors of this method claim superior results when thresholding images
            of neurites and other images that have sparse foreground densities.</dd>
            </dl>
            <dl>
            <dd><img src="images\gear.png">&nbsp;
            This is an implementation of the method described in Padmanabhan <i>et al</i>, 2010.</dd>
            </dl></li>
            </ul>
            
            <p><b>References</b>
            <ul>
            <li>Sezgin M, Sankur B (2004) "Survey over image thresholding techniques and quantitative 
            performance evaluation." <i>Journal of Electronic Imaging</i>, 13(1), 146-165.
            (<a href="https://doi.org/10.1117/1.1631315">link</a>)</li>
            <li>Padmanabhan K, Eddy WF, Crowley JC (2010) "A novel algorithm for
            optimal image thresholding of biological data" <i>Journal of 
            Neuroscience Methods</i> 193, 380-384.
            (<a href="https://doi.org/10.1016/j.jneumeth.2010.08.031">link</a>)</li>
            <li>Ridler T, Calvard S (1978) "Picture thresholding using an iterative selection method",
            <i>IEEE Transactions on Systems, Man and Cybernetics</i>, 8(8), 630-632.</li>
            <li>Kapur JN, Sahoo PK, Wong AKC (1985) "A new method of gray level picture thresholding 
            using the entropy of the histogram." <i>Computer Vision, Graphics and Image Processing</i>, 
            29, 273-285.</li>
            </ul></p>
            </div><h4>Select binary image</h4><div>
            <i>(Used only if Binary image selected for thresholding method)</i><br>
            Select the binary image to be used for thresholding.</div><h4>Manual threshold</h4><div>
            <i>(Used only if Manual selected for thresholding method)</i><br>
            Enter the value that will act as an absolute threshold for the images, a value from 0 to 1.</div><h4>Select the measurement to threshold with</h4><div>
            <i>(Used only if Measurement is selected for thresholding method)</i><br>
            Choose the image measurement that will act as an absolute threshold for the images.</div><h4>Two-class or three-class thresholding?</h4><div>
            <i>(Used only for the Otsu thresholding method)</i> <br>
            <ul>
            <li><i>Two classes:</i> Select this option if the grayscale levels are readily 
            distinguishable into only two classes: foreground (i.e., regions of interest) 
            and background.</li>
            <li><i>Three classes</i>: Choose this option if the grayscale 
            levels fall instead into three classes: foreground, background and a middle intensity
            between the two. You will then be asked whether 
            the middle intensity class should be added to the foreground or background 
            class in order to generate the final two-class output. </li>
            </ul>
            Note that whether 
            two- or three-class thresholding is chosen, the image pixels are always 
            finally assigned two classes: foreground and background.
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            Three-class thresholding may be useful for images in which you have nuclear staining along with 
            low-intensity non-specific cell staining. Where two-class thresholding
            might incorrectly assign this intermediate staining to the nuclei 
            objects for some cells, three-class thresholding allows you to assign it to the 
            foreground or background as desired. </dd>
            </dl>
            <dl>
            <dd><img src="images\thumb-down.png">&nbsp;
            However, in extreme cases where either 
            there are almost no objects or the entire field of view is covered with 
            objects, three-class thresholding may perform worse than two-class.</dd>
            </dl></div><h4>Assign pixels in the middle intensity class to the foreground or the background?</h4><div>
            <i>(Used only for three-class thresholding)</i><br>
            Choose whether you want the pixels with middle grayscale intensities to be assigned 
            to the foreground class or the background class.</div><h4>Approximate fraction of image covered by objects?</h4><div>
            <i>(Used only when applying the MoG thresholding method)</i><br>
            Enter an estimate of how much of the image is covered with objects, which
            is used to estimate the distribution of pixel intensities.</div><h4>Method to calculate adaptive window size</h4><div>
            <i>(Used only if an adaptive thresholding method is used)</i><br>
            The adaptive method breaks the image into blocks, computing the threshold 
            for each block. There are two ways to compute the block size:
            <ul>
            <li><i>Image size:</i> The block size is one-tenth of the image dimensions,
            or 50 &times; 50 pixels, whichever is bigger.</li>
            <li><i>Custom:</i> The block size is specified by the user.</li>
            </ul></div><h4>Size of adaptive window</h4><div>
            <i>(Used only if an adaptive thresholding method with a Custom window size 
            are selected)</i><br>
            Enter the window for the adaptive method. For example,
            you may want to use a multiple of the largest expected object size.</div><h4>Threshold correction factor</h4><div>
            This setting allows you to adjust the threshold as calculated by the
            above method. The value entered here adjusts the threshold either 
            upwards or downwards, by multiplying it by this value. 
            A value of 1 means no adjustment, 0 to 1 makes the threshold more 
            lenient and &gt; 1 makes the threshold more stringent. 
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            When the threshold is calculated automatically, you may find that 
            the value is consistently too stringent or too lenient across all
            images. This setting
            is helpful for adjusting the threshold to a value that you empirically 
            determine is more suitable. For example, the
            Otsu automatic thresholding inherently assumes that 50% of the image is
            covered by objects. If a larger percentage of the image is covered, the
            Otsu method will give a slightly biased threshold that may have to be
            corrected using this setting.</dd>
            </dl></div><h4>Lower and upper bounds on threshold</h4><div>
            Enter the minimum and maximum allowable threshold, a value from 0 to 1.  
            This is helpful as a safety precaution when the threshold is calculated
            automatically, by overriding the automatic threshold.
            <dl>
            <dd><img src="images\thumb-up.png">&nbsp;
            For example, if there are no objects in the field of view,
            the automatic threshold might be calculated as unreasonably low; the algorithm will
            still attempt to divide the foreground from background (even though there is no
            foreground), and you may end up with spurious false positive foreground regions.
            In such cases, you can estimate the background pixel intensity and set the lower
            bound according to this empirically-determined value. </dd>
            <dd>To view pixel intensities in an open image, use the 
pixel intensity tool which is available in any open display window. When you move 
your mouse over the image, the pixel intensities will appear in the bottom bar of the display window.</dd>
            </dl></div><h4>Select the smoothing method for thresholding</h4><div>
            <i>(Only used for strategies other than Automatic and
            Binary image)</i><br>
            The input image can be optionally smoothed before being thresholded.
            Smoothing can improve the uniformity of the resulting objects, by 
            removing holes and jagged edges caused by noise in the acquired image. 
            Smoothing is most likely <i>not</i> appropriate if the input image is 
            binary, if it has already been smoothed or if it is an output of the
            <i>ClassifyPixels</i> module.<br>
            The choices are:
            <ul>
            <li><i>Automatic</i>: Smooth the image with a Gaussian
            with a sigma of one pixel before thresholding. This is suitable
            for most analysis applications.</li>
            <li><i>Manual</i>: Smooth the image with a Gaussian with
            user-controlled scale.</li>
            <li><i>No smoothing</i>: Do not apply any smoothing prior to 
            thresholding.</li>
            </ul></div><h4>Threshold smoothing scale</h4><div>
            <i>(Only used if smoothing for threshold is Manual)</i><br>
            This setting controls the scale used to smooth the input image
            before the threshold is applied. The scale should be approximately
            the size of the artifacts to be eliminated by smoothing. A Gaussian
            is used with a sigma adjusted so that 1/2 of the Gaussian's
            distribution falls within the diameter given by the scale
            (sigma = scale / 0.674)</div></div>

<div><p><img src="images\ApplyThreshold.png", width="50%"></p></div>
</body></html>